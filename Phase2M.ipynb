{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-26T12:27:14.863351Z",
     "start_time": "2024-10-26T12:27:14.588298Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 2: Data preprocessing",
   "id": "87f08b3907cc03bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## First we redo the data changes from the 1st phase",
   "id": "e14ff616e53bc87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:29:42.646625Z",
     "start_time": "2024-10-26T15:29:42.498204Z"
    }
   },
   "cell_type": "code",
   "source": "connections, devices, processes, profiles = pd.read_csv('data/connections.csv', sep='\\t', keep_default_na=False, na_values=''), pd.read_csv('data/devices.csv', sep='\\t', keep_default_na=False, na_values=''), pd.read_csv('data/processes.csv', sep='\\t', keep_default_na=False, na_values=''), pd.read_csv('data/profiles.csv', sep='\\t', keep_default_na=False, na_values='')",
   "id": "29387cee1bcc3fa4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Iterative way to redo the changes:",
   "id": "621d25b7e9625cb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:29:44.222180Z",
     "start_time": "2024-10-26T15:29:44.215883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_outliers(column: pd.Series):\n",
    "    lower_quartile = column.quantile(0.25)\n",
    "    upper_quartile = column.quantile(0.75)\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "    return column[(column < lower_quartile - 1.5*iqr) | (column > upper_quartile + 1.5*iqr)]\n"
   ],
   "id": "fb4d0f16b6c55ae4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:38:24.542875Z",
     "start_time": "2024-10-26T15:38:24.531742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def iterative_reformat(processes_ptr: pd.DataFrame, connections_ptr: pd.DataFrame) -> pd.DataFrame:\n",
    "    connections_ptr['ts'] = pd.to_datetime(connections_ptr['ts'])\n",
    "    processes_ptr['ts'] = pd.to_datetime(processes_ptr['ts'])\n",
    "    merged = processes_ptr.merge(connections_ptr, on=['ts', 'imei', 'mwra'], how='inner')\n",
    "    merged.drop(columns=['ts', 'imei'], inplace=True)\n",
    "    to_drop = []\n",
    "    # handle null values and outliers\n",
    "    for column in merged.columns:\n",
    "        # if more than 5% are NaN values or more than 5% are outliers, we don't use that column\n",
    "        column_outliers = get_outliers(merged[column])\n",
    "        if ((merged[column].isna().sum()/merged.shape[0] > 0.05) or \n",
    "            (column_outliers.shape[0] / merged.shape[0] > 0.05)):\n",
    "            to_drop.append(column)\n",
    "            continue\n",
    "        # if there are some null values, we replace the data that's neutral in respect to mwra\n",
    "        if merged[column].isnull().any():\n",
    "            # we get means of the distributions for rows with present and non-present malware related activity\n",
    "            means_per_mwra = merged.groupby('mwra')[column].mean()\n",
    "            # we average those means, meaning the manufactured value won't be likely to affect predicted mwra \n",
    "            imputed_value = means_per_mwra.mean()\n",
    "            merged[column].fillna(imputed_value, inplace=True)\n",
    "        #  if there are any outliers, we replace them with the edge values\n",
    "        if column_outliers.shape[0]:\n",
    "            iqr = stats.iqr(merged[column])\n",
    "            lower_limit = merged[column].quantile(0.25)  - 1.5 * iqr\n",
    "            upper_limit = merged[column].quantile(0.75)  - 1.5 * iqr\n",
    "            merged[column] = merged[column].clip(lower=lower_limit, upper=upper_limit)\n",
    "    return merged.drop(columns=to_drop)"
   ],
   "id": "3d3773f998dabebe",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 2-1: Realizing data preprocessing",
   "id": "f4b354aa3ab72ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2-1a & 2-1b\n",
    "Splitting the data into training and testing sets + transforming data for ML"
   ],
   "id": "28dbdd10be58dd2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we create a combined table for data to work with. As we learnt in the previous phase, we will use only connections and processes tables. Devices and profiles couldn't be connected logically with the other two tables. That's because there were multiple profiles/devices per imei. And it wasn't a fixed amount of profiles/devices per imei either, so we can't just make a column for all locations/usernames/etc. Even if we did that, there wasn't a correlation found between any of the columns in these tables and mwra.",
   "id": "305615d97cc5b489"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:38:30.527376Z",
     "start_time": "2024-10-26T15:38:30.396100Z"
    }
   },
   "cell_type": "code",
   "source": "combined_table = iterative_reformat(processes, connections)",
   "id": "6eed37a2981f13ae",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "now onto splitting the data into testing and training",
   "id": "4767938d6652d569"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:38:32.243453Z",
     "start_time": "2024-10-26T15:38:32.229030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we separate the features and the target\n",
    "X = combined_table.drop(columns=['mwra'])\n",
    "y = combined_table['mwra']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ],
   "id": "bf593ed12f12b4f4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we didn't use any non-numerical data, we don't need to do any conversions to numerical. Most of the data had huge cardinality either way which would increase likelihood of overfitting and difficulty of encoding. ",
   "id": "e6b227ee766836ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example for what we would do if we were to use the categorical data from profiles and devices table",
   "id": "be04272d98313d38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T15:38:33.874130Z",
     "start_time": "2024-10-26T15:38:33.861888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if the cardinality was too high to use one hot encoding, we can hash the values and now they are numbers\n",
    "mail_encoded = profiles['mail'].apply(lambda x: hash(x))\n",
    "profiles['mail'].nunique(), mail_encoded.nunique()\n",
    "# if one hot encoding was feasible, it could be doable like this\n",
    "continents = devices[\"location\"].apply(lambda x: x.split('/')[0])\n",
    "continents.head()"
   ],
   "id": "f9749fe466196039",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      America\n",
       "1    Australia\n",
       "2       Europe\n",
       "3       Europe\n",
       "4      America\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
